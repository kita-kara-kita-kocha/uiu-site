#!/usr/bin/env python3
"""
ãƒ•ã‚¡ãƒ³ã‚µã‚¤ãƒˆå‹•ç”»æƒ…å ±å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Webãƒšãƒ¼ã‚¸ã€Œhttps://candfans.jp/iu_nyaaã€ã‚’é–‹ãã€ä¸€ç•ªä¸‹ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ãŸçŠ¶æ…‹ã§
ã™ã¹ã¦ã®divã‚¿ã‚°ãƒ»class="grid grid-cols-2 gap-x-1 gap-y-3 pt-2 items-end"
ã®å­è¦ç´ (ã‚µãƒ ãƒã‚¤ãƒ«)ã‹ã‚‰æŠ•ç¨¿æƒ…å ±
    å‹•ç”»ãªã‚‰
    ãƒ»è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
    ãƒ»è¨˜äº‹URL
    ãƒ»ã‚µãƒ ãƒã‚¤ãƒ«URL
    ãƒ»metaæƒ…å ±(é–²è¦§å›æ•°ã€æŠ•ç¨¿æ™‚æœŸã€å‹•ç”»æ™‚é–“)
    ç”»åƒãªã‚‰
    ãƒ»è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
    ãƒ»è¨˜äº‹URL
    ãƒ»ã‚µãƒ ãƒã‚¤ãƒ«URL
    ãƒ»metaæƒ…å ±(é–²è¦§å›æ•°ã€æŠ•ç¨¿æ™‚æœŸ)
ã‚’å–å¾—ã—ã€
docs/secret_ac.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ã€‚
"""

import json
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
import time
from datetime import datetime
import sys

# è¨­å®š
SECRET_PAGE_URL = "https://candfans.jp/iu_nyaa"
OUTPUT_FILE = "../docs/secret_ac.json"

class SecretVideoInfoExtractor:
    def __init__(self):
        self.setup_driver()

    def setup_driver(self):
        """
        Selenium WebDriverã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        """
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
        
        try:
            # WebDriverManagerã‚’ä½¿ç”¨ã—ã¦ChromeDriverã‚’è‡ªå‹•ç®¡ç†
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.wait = WebDriverWait(self.driver, 10)
        except Exception as e:
            print(f"WebDriverã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
            print("ChromeDriverManagerãŒä½¿ç”¨ã§ããªã„å ´åˆã¯ã€æ‰‹å‹•ã§ChromeDriverã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
            try:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥Chromeã‚’ä½¿ç”¨
                self.driver = webdriver.Chrome(options=chrome_options)
                self.wait = WebDriverWait(self.driver, 10)
            except Exception as e2:
                print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã®WebDriveråˆæœŸåŒ–ã‚‚å¤±æ•—: {e2}")
                sys.exit(1)

    def scroll_to_bottom(self):
        """
        ãƒšãƒ¼ã‚¸ã®ä¸€ç•ªä¸‹ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦ã€ã™ã¹ã¦ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã‚€
        """
        print("ãƒšãƒ¼ã‚¸ã®ä¸€ç•ªä¸‹ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­...")
        
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        
        while True:
            # ä¸€ç•ªä¸‹ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            
            # æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã¾ã§å¾…æ©Ÿï¼ˆé…å»¶èª­ã¿è¾¼ã¿å¯¾å¿œï¼‰
            time.sleep(5)
            
            # æ–°ã—ã„ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«é«˜ã•ã‚’å–å¾—
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            
            # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«é«˜ã•ãŒå¤‰ã‚ã‚‰ãªã‘ã‚Œã°çµ‚äº†
            if new_height == last_height:
                print("ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å®Œäº†")
                break
                
            last_height = new_height
        
        # æœ€å¾Œã«ã‚‚ã†ä¸€åº¦å¾…æ©Ÿã—ã¦ã€ã™ã¹ã¦ã®ç”»åƒãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã®ã‚’å¾…ã¤
        print("ç”»åƒã®é…å»¶èª­ã¿è¾¼ã¿å®Œäº†ã‚’å¾…æ©Ÿä¸­...")
        
        # é…å»¶èª­ã¿è¾¼ã¿ç”»åƒã‚’å¼·åˆ¶çš„ã«ãƒˆãƒªã‚¬ãƒ¼
        try:
            self.driver.execute_script("""
                // ã™ã¹ã¦ã®imgè¦ç´ ã«å¯¾ã—ã¦ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒˆãƒªã‚¬ãƒ¼
                const images = document.querySelectorAll('img');
                images.forEach(img => {
                    if (img.dataset.src || img.dataset.lazySrc || img.dataset.original) {
                        img.scrollIntoView();
                    }
                });
                
                // Intersection Observer APIãŒä½¿ã‚ã‚Œã¦ã„ã‚‹å ´åˆã®å¯¾å¿œ
                window.dispatchEvent(new Event('scroll'));
                window.dispatchEvent(new Event('resize'));
            """)
        except Exception as e:
            print(f"ç”»åƒèª­ã¿è¾¼ã¿ãƒˆãƒªã‚¬ãƒ¼ã§ã‚¨ãƒ©ãƒ¼: {e}")
        
        time.sleep(10)

    def extract_post_info_from_element(self, element):
        """
        å˜ä¸€ã®æŠ•ç¨¿è¦ç´ ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
        """
        post_info = {}
        
        try:
            # æŠ•ç¨¿ã®ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šï¼ˆå‹•ç”»ã‹ç”»åƒã‹ï¼‰
            post_type = "image"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç”»åƒ
            
            # å‹•ç”»æ™‚é–“ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            duration_selectors = [
                "[class*='duration']", ".duration", "[data-duration]",
                ".time", "[class*='time']", ".video-time"
            ]
            
            for selector in duration_selectors:
                try:
                    duration_elements = element.find_elements(By.CSS_SELECTOR, selector)
                    for duration_elem in duration_elements:
                        duration_text = duration_elem.text.strip()
                        # æ™‚é–“å½¢å¼ (mm:ss ã¾ãŸã¯ hh:mm:ss) ã‚’ãƒã‚§ãƒƒã‚¯
                        if duration_text and ":" in duration_text and len(duration_text) >= 4:
                            # æ•°å­—ã¨:ã®ã¿ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                            import re
                            if re.match(r'^\d{1,2}:\d{2}(:\d{2})?$', duration_text):
                                post_type = "video"
                                post_info['duration'] = duration_text
                                break
                    if post_type == "video":
                        break
                except Exception:
                    continue
            
            # ãƒ“ãƒ‡ã‚ªã‚¿ã‚°ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            try:
                video_elements = element.find_elements(By.TAG_NAME, "video")
                if video_elements:
                    post_type = "video"
            except Exception:
                pass
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ï¼ˆè¤‡æ•°ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œï¼‰
            title_selectors = [
                "h1", "h2", "h3", "h4", "h5", "h6",
                "[class*='title']", "[class*='Title']",
                "p", "span", "div", "a"
            ]
            
            title_found = False
            for selector in title_selectors:
                try:
                    title_elements = element.find_elements(By.CSS_SELECTOR, selector)
                    for title_elem in title_elements:
                        title_text = title_elem.text.strip()
                        if title_text and len(title_text) > 3 and len(title_text) < 200:
                            post_info['title'] = title_text
                            title_found = True
                            break
                    if title_found:
                        break
                except Exception:
                    continue
            
            # æŠ•ç¨¿ãƒªãƒ³ã‚¯ã‚’å–å¾—
            try:
                link_element = element.find_element(By.TAG_NAME, "a")
                if link_element:
                    href = link_element.get_attribute('href')
                    if href:
                        post_info['video_url'] = href
            except Exception:
                pass
            
            # ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã‚’å–å¾—
            try:
                img_elements = element.find_elements(By.TAG_NAME, "img")
                for img_element in img_elements:
                    # è¤‡æ•°ã®å±æ€§ã‹ã‚‰ç”»åƒURLã‚’å–å¾—
                    src_candidates = [
                        img_element.get_attribute('src'),
                        img_element.get_attribute('data-src'),
                        img_element.get_attribute('data-lazy-src'),
                        img_element.get_attribute('data-original'),
                        img_element.get_attribute('data-url'),
                        img_element.get_attribute('srcset')  # srcsetã‹ã‚‰æœ€åˆã®URLã‚’æŠ½å‡º
                    ]
                    
                    valid_src = None
                    for src in src_candidates:
                        if (src and 
                            'progress-circle' not in src and 
                            'loading' not in src.lower() and
                            'placeholder' not in src.lower() and
                            src.startswith(('http', '//'))):
                            # srcsetã®å ´åˆã¯æœ€åˆã®URLã‚’å–å¾—
                            if 'srcset' in str(src):
                                src = src.split(',')[0].split(' ')[0]
                            valid_src = src
                            break
                    
                    if valid_src:
                        post_info['image'] = valid_src
                        break
                        
                # altå±æ€§ã‚‚å–å¾—
                if img_elements:
                    alt = img_elements[0].get_attribute('alt')
                    if alt:
                        post_info['alt'] = alt
            except Exception:
                pass

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆé–²è¦§å›æ•°ã€æŠ•ç¨¿æ™‚æœŸãªã©ï¼‰
            metadata = []
            
            # æ—¥æ™‚æƒ…å ±ã‚’æ¢ã™
            date_selectors = [
                "time", ".date", ".datetime", "[datetime]",
                "[class*='date']", "[class*='time']", "[class*='publish']"
            ]
            
            # for selector in date_selectors:
            #     try:
            #         date_elements = element.find_elements(By.CSS_SELECTOR, selector)
            #         for date_elem in date_elements:
            #             date_text = date_elem.text.strip()
            #             if date_text and len(date_text) > 0:
            #                 metadata.append(f"æŠ•ç¨¿æ—¥æ™‚: {date_text}")
            #                 break
            #     except Exception:
            #         continue
            
            # é–²è¦§å›æ•°ã‚’æ¢ã™
            view_selectors = [
                "[class*='view']", "[class*='count']", "[class*='number']"
            ]
            
            for selector in view_selectors:
                try:
                    view_elements = element.find_elements(By.CSS_SELECTOR, selector)
                    for view_elem in view_elements:
                        view_text = view_elem.text.strip()
                        if view_text and any(keyword in view_text.lower() for keyword in ['å›', 'view', 'count', 'ä¸‡', 'åƒ']):
                            metadata.append(f"é–²è¦§å›æ•°: {view_text}")
                            break
                except Exception:
                    continue
            
            # ãã®ä»–ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
            meta_elements = element.find_elements(By.CSS_SELECTOR, "span, div, p")
            for meta_elem in meta_elements[:5]:
                meta_text = meta_elem.text.strip()
                if (meta_text and 
                    len(meta_text) < 100 and 
                    meta_text not in [post_info.get('title', '')] and
                    meta_text not in metadata):
                    metadata.append(meta_text)
                if len(metadata) >= 5:
                    break
            
            if metadata:
                post_info['metadata'] = metadata
            
            # æŠ•ç¨¿ã‚¿ã‚¤ãƒ—ã‚’è¨­å®š
            post_info['type'] = post_type
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯æŠ•ç¨¿URLãŒã‚ã‚‹å ´åˆã®ã¿è¿”ã™
            if post_info.get('title') or post_info.get('video_url'):
                return post_info
                
        except Exception as e:
            print(f"æŠ•ç¨¿æƒ…å ±ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼: {e}")
            
        return None

    def extract_all_post_info(self):
        """
        ãƒšãƒ¼ã‚¸ã‹ã‚‰ã™ã¹ã¦ã®æŠ•ç¨¿æƒ…å ±ã‚’æŠ½å‡º
        """
        print(f"ãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ä¸­: {SECRET_PAGE_URL}")
        
        try:
            # ãƒšãƒ¼ã‚¸ã‚’é–‹ã
            self.driver.get(SECRET_PAGE_URL)
            
            # ãƒšãƒ¼ã‚¸ãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
            time.sleep(5)
            
            # å¹´é½¢èªè¨¼ã‚„ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ãªå ´åˆã®å‡¦ç†
            try:
                print("ãƒšãƒ¼ã‚¸ã®åˆæœŸå‡¦ç†ã‚’ç¢ºèªä¸­...")
                
                # å¹´é½¢èªè¨¼ã€åŒæ„ãƒœã‚¿ãƒ³ãªã©ã‚’æ¢ã—ã¦æŠ¼ã™
                consent_selectors = [
                    "button[aria-label*='ç¢ºèª']",
                    "button[aria-label*='åŒæ„']", 
                    "button[data-testid*='confirm']",
                    "button:contains('ã¯ã„')",
                    "button:contains('åŒæ„')",
                    "button:contains('ç¢ºèª')",
                    "button:contains('OK')",
                    ".btn", ".button",
                    "input[type='submit']"
                ]
                
                for selector in consent_selectors:
                    try:
                        buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        for button in buttons:
                            button_text = button.text.strip().lower()
                            if any(keyword in button_text for keyword in ['ã¯ã„', 'åŒæ„', 'ç¢ºèª', 'yes', 'confirm', 'agree', 'ok']):
                                print(f"åŒæ„ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯: {button_text}")
                                button.click()
                                time.sleep(2)
                                break
                    except Exception:
                        continue
                        
            except Exception as e:
                print(f"åˆæœŸå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®èª­ã¿è¾¼ã¿å®Œäº†ã‚’å¾…æ©Ÿ
            time.sleep(10)
            
            # ä¸€ç•ªä¸‹ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
            self.scroll_to_bottom()
            
            # ãƒšãƒ¼ã‚¸ã®æ§‹é€ ã‚’ãƒ‡ãƒãƒƒã‚°
            print("ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«:", self.driver.title)
            print("ãƒšãƒ¼ã‚¸URL:", self.driver.current_url)
            
            # å¯¾è±¡ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’æ¢ã™
            container_selectors = [
                "div.grid.grid-cols-2.gap-x-1.gap-y-3.pt-2.items-end",
                ".grid.grid-cols-2",
                ".grid-cols-2",
                "[class*='grid']",
                "[class*='cols-2']"
            ]
            
            container = None
            working_selector = None
            
            for selector in container_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        print(f"ã‚»ãƒ¬ã‚¯ã‚¿ '{selector}' ã§ {len(elements)} å€‹ã®è¦ç´ ã‚’ç™ºè¦‹")
                        # å­è¦ç´ ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        for element in elements:
                            children = element.find_elements(By.XPATH, "./*")
                            if len(children) > 0:
                                print(f"å­è¦ç´  {len(children)} å€‹ã‚’æŒã¤ã‚³ãƒ³ãƒ†ãƒŠã‚’ç™ºè¦‹")
                                container = element
                                working_selector = selector
                                break
                        if container:
                            break
                except Exception as e:
                    print(f"ã‚»ãƒ¬ã‚¯ã‚¿ '{selector}' ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
            if container is None:
                print("å¯¾è±¡ã‚³ãƒ³ãƒ†ãƒŠãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ã®æ§‹é€ ã‚’ç¢ºèªã—ã¾ã™ã€‚")
                
                # ã™ã¹ã¦ã®divè¦ç´ ã‚’ç¢ºèª
                all_divs = self.driver.find_elements(By.TAG_NAME, "div")
                print(f"ãƒšãƒ¼ã‚¸å†…ã®divè¦ç´ æ•°: {len(all_divs)}")
                
                # gridé–¢é€£ã®ã‚¯ãƒ©ã‚¹ã‚’æŒã¤è¦ç´ ã‚’æ¢ã™
                grid_elements = self.driver.find_elements(By.CSS_SELECTOR, "[class*='grid']")
                print(f"gridé–¢é€£ã®è¦ç´ æ•°: {len(grid_elements)}")
                
                if grid_elements:
                    print("gridè¦ç´ ã®ã‚¯ãƒ©ã‚¹åã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
                    for i, grid_elem in enumerate(grid_elements[:5]):
                        class_name = grid_elem.get_attribute('class')
                        children_count = len(grid_elem.find_elements(By.XPATH, "./*"))
                        print(f"Gridè¦ç´  {i+1}: class='{class_name}', å­è¦ç´ ={children_count}å€‹")
                        
                        if children_count > 0:
                            container = grid_elem
                            working_selector = f"gridè¦ç´ {i+1}"
                            break
                
                if container is None:
                    return []
            
            print(f"å¯¾è±¡ã‚³ãƒ³ãƒ†ãƒŠã‚’ç™ºè¦‹: {working_selector}")
            
            # å­è¦ç´ ï¼ˆæŠ•ç¨¿ï¼‰ã‚’å–å¾—
            post_elements = container.find_elements(By.XPATH, "./*")
            print(f"{len(post_elements)} å€‹ã®æŠ•ç¨¿è¦ç´ ã‚’ç™ºè¦‹")
            
            post_list = []
            for i, element in enumerate(post_elements):
                # 10å€‹ã”ã¨ã«é€²æ—ã‚’å ±å‘Š
                if i % 10 == 0:
                    print(f"\n=== é€²æ—: {i+1}/{len(post_elements)} å‡¦ç†ä¸­ ===")
                
                post_info = self.extract_post_info_from_element(element)
                if post_info:
                    post_list.append(post_info)
                    post_type = post_info.get('type', 'unknown')
                    title = post_info.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')[:50]
                    print(f"âœ“ {i+1}: [{post_type}] {title}...")
                else:
                    print(f"âœ— {i+1}: æŠ•ç¨¿æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                time.sleep(0.1)
            
            return post_list
            
        except Exception as e:
            print(f"æŠ•ç¨¿æƒ…å ±ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            import traceback
            traceback.print_exc()
            return []

    def save_to_json(self, post_list, filename=OUTPUT_FILE):
        """
        æŠ•ç¨¿æƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆ{"items": []} å½¢å¼ï¼‰
        """
        try:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            output_path = Path(filename)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # {"items": []} å½¢å¼ã§ä¿å­˜
            data = {"items": post_list}
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
            print(f"æŠ•ç¨¿æƒ…å ±ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
        except Exception as e:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—: {e}")

    def close(self):
        """
        WebDriverã‚’é–‰ã˜ã‚‹
        """
        if hasattr(self, 'driver'):
            self.driver.quit()

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
    start_time = datetime.now()

    print("ğŸ¬ ãƒ•ã‚¡ãƒ³ã‚µã‚¤ãƒˆå‹•ç”»æƒ…å ±å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")

    extractor = SecretVideoInfoExtractor()
    
    try:
        # å…¨æŠ•ç¨¿æƒ…å ±ã‚’å–å¾—
        all_posts = extractor.extract_all_post_info()
        
        print(f"\nåˆè¨ˆ {len(all_posts)} å€‹ã®æŠ•ç¨¿æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
        
        # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        extractor.save_to_json(all_posts)
        
        # å–å¾—ã—ãŸæƒ…å ±ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
        if all_posts:
            print("\nå–å¾—ã—ãŸæŠ•ç¨¿æƒ…å ±ã®ã‚µãƒ³ãƒ—ãƒ«:")
            
            # å‹•ç”»ã¨ç”»åƒã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            video_count = len([p for p in all_posts if p.get('type') == 'video'])
            image_count = len([p for p in all_posts if p.get('type') == 'image'])
            print(f"å‹•ç”»: {video_count}å€‹, ç”»åƒ: {image_count}å€‹")
            
            # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°SVGå•é¡Œã®ãƒã‚§ãƒƒã‚¯
            loading_count = len([p for p in all_posts if p.get('image', '').find('progress-circle') != -1])
            if loading_count > 0:
                print(f"âš ï¸ è­¦å‘Š: {loading_count}å€‹ã®æŠ•ç¨¿ã§ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°SVGãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            
            for i, post in enumerate(all_posts[:3]):  # æœ€åˆã®3ä»¶ã‚’è¡¨ç¤º
                print(f"\n--- æŠ•ç¨¿ {i+1} [{post.get('type', 'unknown')}] ---")
                print(f"ã‚¿ã‚¤ãƒˆãƒ«: {post.get('title', 'N/A')}")
                print(f"æŠ•ç¨¿URL: {post.get('post_url', 'N/A')}")
                print(f"ã‚µãƒ ãƒã‚¤ãƒ«: {post.get('image', 'N/A')}")
                if post.get('duration'):
                    print(f"å‹•ç”»æ™‚é–“: {post['duration']}")
                if post.get('metadata'):
                    print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {post['metadata'][:2]}")  # æœ€åˆã®2ã¤ã®ã¿è¡¨ç¤º
                    
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)
        
    finally:
        extractor.close()
        # å®Ÿè¡Œæ™‚é–“ã‚’è¡¨ç¤º
        end_time = datetime.now()
        execution_time = end_time - start_time
        print(f"\nâ± å®Ÿè¡Œæ™‚é–“: {execution_time}")
        print("ğŸ‰ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()
