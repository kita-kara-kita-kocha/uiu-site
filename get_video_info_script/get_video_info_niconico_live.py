#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import json
import time
import re
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse, parse_qs
from datetime import datetime
import sys

# è¨­å®š
CHANNEL_URL = "https://ch.nicovideo.jp/uise-iu/live"
OUTPUT_FILE = "../docs/niconico_l.json"

class NiconicoLiveVideoInfoExtractor:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })

    def get_total_pages(self, base_url):
        """
        ãƒãƒ£ãƒ³ãƒãƒ«ãƒšãƒ¼ã‚¸ã‹ã‚‰ç·ãƒšãƒ¼ã‚¸æ•°ã‚’å–å¾—
        """
        try:
            response = self.session.get(base_url)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰æœ€çµ‚ãƒšãƒ¼ã‚¸ç•ªå·ã‚’å–å¾—
            pagination = soup.find('ul', class_='pagination')
            if pagination:
                page_links = pagination.find_all('a')
                page_numbers = []
                for link in page_links:
                    href = link.get('href', '')
                    if 'page=' in href:
                        match = re.search(r'page=(\d+)', href)
                        if match:
                            page_numbers.append(int(match.group(1)))
                
                if page_numbers:
                    return max(page_numbers)
            
            # ä»£æ›¿æ–¹æ³•: æœ€çµ‚ãƒšãƒ¼ã‚¸ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™
            last_page_link = soup.find('a', string=re.compile(r'æœ€å¾Œ'))
            if last_page_link:
                href = last_page_link.get('href', '')
                match = re.search(r'page=(\d+)', href)
                if match:
                    return int(match.group(1))
                    
            return 1
            
        except Exception as e:
            print(f"ç·ãƒšãƒ¼ã‚¸æ•°ã®å–å¾—ã«å¤±æ•—: {e}")
            return 1

    def extract_video_info_from_page(self, url):
        """
        æŒ‡å®šã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‹ã‚‰å‹•ç”»æƒ…å ±ã‚’æŠ½å‡º
        """
        video_list = []
        
        try:
            page = 0
            video_items = []
            while True:
                page += 1
                response = self.session.get(f'{url}?page={page}')
                response.raise_for_status()
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # å‹•ç”»ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¢ã™ï¼ˆãƒ‹ã‚³ãƒ‹ã‚³ç”Ÿæ”¾é€ã®HTMLæ§‹é€ ã«åŸºã¥ãï¼‰
                # sectionã‚¿ã‚°ã®classãŒsubã‹ã¤pastã®ä¸¡æ–¹ã‚’æŒã¤ã‚‚ã®ã‚’æ¢ã™
                section_items = soup.find_all('section', class_=lambda x: x and 'sub' in x and 'past' in x)
                if not section_items:
                    print(f"ãƒšãƒ¼ã‚¸ {page} ã§å‹•ç”»ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                tmp_items = []
                for section in section_items:
                    tmp_items = section.find_all('div', class_='item')
                    print(f"ãƒšãƒ¼ã‚¸ {page} ã‹ã‚‰ {len(tmp_items)} å€‹ã®å‹•ç”»ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¤œå‡º")
                    video_items.extend(tmp_items)
                if len(tmp_items) == 0:
                    print(f"ãƒšãƒ¼ã‚¸ {page} ã§å‹•ç”»ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚çµ‚äº†ã—ã¾ã™ã€‚")
                    break
            for item in video_items:
                try:
                    video_info = self.extract_single_video_info(item)
                    print(f"å‹•ç”»æƒ…å ±ã‚’æŠ½å‡º: {video_info}")
                    if video_info:
                        video_list.append(video_info)
                except Exception as e:
                    print(f"å‹•ç”»æƒ…å ±ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
                        
        except Exception as e:
            print(f"ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã«å¤±æ•— ({url}): {e}")
            
        return video_list

    def extract_single_video_info(self, item):
        """
        å˜ä¸€ã®å‹•ç”»ã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
        """
        video_info = {}
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã®å–å¾—
        title_element = item.find('h3') or item.find('h2') or item.find('a', class_=re.compile(r'.*title.*'))
        if title_element:
            video_info['title'] = title_element.get_text(strip=True)
        
        # å‹•ç”»ãƒªãƒ³ã‚¯ã®å–å¾—
        link_element = item.find('a', href=re.compile(r'/watch/'))
        if link_element:
            href = link_element.get('href')
            if href.startswith('/'):
                video_info['video_url'] = f"https://live.nicovideo.jp{href}"
            else:
                video_info['video_url'] = href
        
        # ã‚µãƒ ãƒã‚¤ãƒ«ã®å–å¾—
        img_element = item.find('img')
        if img_element:
            src = img_element.get('src') or img_element.get('data-src')
            if src:
                if src.startswith('/'):
                    video_info['image'] = f"https:{src}"
                elif src.startswith('//'):
                    video_info['image'] = f"https:{src}"
                else:
                    video_info['image'] = src

        # metadateã®å®šç¾©
        video_info['metadata'] = []
        
        # æ”¾é€é–‹å§‹æ—¥æ™‚ã®å–å¾—
        # pã‚¿ã‚°class=dateã®è¦ç´ ã‚’æ¢ã™
        date_element = item.find('p', class_='date')
        # ulã‚¿ã‚°ã‹ã‚‰class=itemsã®è¦ç´ ã‚’æ¢ã™
        if date_element:
            # date_elementã®ç©ºç™½ã‚’å‰Šé™¤
            date_element = date_element.get_text(strip=True)
            # æ”¾é€é–‹å§‹ï¼š2025/07/03 (æœ¨) 00:00:00ã‹ã‚‰2025/07/03 (æœ¨) 00:00:00ã®éƒ¨åˆ†ã‚’æŠ½å‡º
            date_element = date_element.split('ï¼š')[-1]
            video_info['metadata'].append(f"æ”¾é€é–‹å§‹: {date_element}")

        # ã‚¿ã‚¤ãƒ ã‚·ãƒ•ãƒˆè¦–è´æœŸé™ã®å–å¾—
        # video_info['video_url']ã‹ã‚‰å‹•ç”»IDã®æŠ½å‡º
        # ~~/watch/lv348141543 ã®å½¢å¼ã‹ã‚‰lv348141543ã‚’æŠ½å‡º
        video_id = video_info['video_url'].split('/')[-1]
        # https://ch.nicovideo.jp/uise-iu/live/{video_id}?ref=WatchPage-ProgramPaymentInformation-PaymentActionMenu-NetTicketPurchaseOrChannelJoiningAnchor ã§ã‚¿ã‚¤ãƒ ã‚·ãƒ•ãƒˆè¦–è´æœŸé™ã®æƒ…å ±ã‚’ç¢ºèªå¯èƒ½
        ts_check_url = f"https://ch.nicovideo.jp/uise-iu/live/{video_id}?ref=WatchPage-ProgramPaymentInformation-PaymentActionMenu-NetTicketPurchaseOrChannelJoiningAnchor"
        try:
            ts_response = self.session.get(ts_check_url)
            ts_response.raise_for_status()
            ts_soup = BeautifulSoup(ts_response.text, 'html.parser')
            
            # ã‚¿ã‚¤ãƒ ã‚·ãƒ•ãƒˆè¦–è´æœŸé™ã®è¦ç´ ã‚’æ¢ã™
            timeshift_limit_element_ = ts_soup.find_all('dt', text=re.compile(r'ã‚¿ã‚¤ãƒ ã‚·ãƒ•ãƒˆè¦–è´æœŸé™ï¼š'))
            # timeshift_limit_element_ã®è¦ªè¦ç´ ã‹ã‚‰ddè¦ç´ ã‚’å–å¾—
            timeshift_limit_element = timeshift_limit_element_[0].find_next('dd')
            video_info['metadata'].append(f"ã‚¿ã‚¤ãƒ ã‚·ãƒ•ãƒˆè¦–è´æœŸé™: {timeshift_limit_element.get_text(strip=True)}")
        except Exception as e:
            print(f"ã‚¿ã‚¤ãƒ ã‚·ãƒ•ãƒˆè¦–è´æœŸé™ã®å–å¾—ã«å¤±æ•—: {e}")
            video_info['metadata'].append('ã‚¿ã‚¤ãƒ ã‚·ãƒ•ãƒˆè¦–è´æœŸé™: ä¸æ˜')
        
        # æœ€ä½é™å¿…è¦ãªæƒ…å ±ãŒã‚ã‚‹å ´åˆã®ã¿è¿”ã™
        if video_info.get('title') and video_info.get('video_url'):
            return video_info
        
        return None

    def get_all_video_info(self, base_url):
        """
        å…¨ãƒšãƒ¼ã‚¸ã‹ã‚‰å‹•ç”»æƒ…å ±ã‚’å–å¾—
        """
        print(f"å‹•ç”»æƒ…å ±ã®å–å¾—ã‚’é–‹å§‹: {base_url}")
        
        all_videos = []
        total_pages = self.get_total_pages(base_url)
        
        print(f"ç·ãƒšãƒ¼ã‚¸æ•°: {total_pages}")
        
        for page in range(1, total_pages + 1):
            if page == 1:
                url = base_url
            else:
                separator = '&' if '?' in base_url else '?'
                url = f"{base_url}{separator}page={page}"
            
            print(f"ãƒšãƒ¼ã‚¸ {page}/{total_pages} ã‚’å‡¦ç†ä¸­: {url}")
            
            page_videos = self.extract_video_info_from_page(url)
            all_videos.extend(page_videos)
            
            print(f"ãƒšãƒ¼ã‚¸ {page} ã‹ã‚‰ {len(page_videos)} å€‹ã®å‹•ç”»æƒ…å ±ã‚’å–å¾—")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            time.sleep(1)
        
        return all_videos

    def save_to_json(self, video_list, filename=OUTPUT_FILE):
        """
        å‹•ç”»æƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        """
        try:
            # {"items": []} å½¢å¼ã§ä¿å­˜
            data = {"items": video_list}
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"å‹•ç”»æƒ…å ±ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—: {e}")

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
    start_time = datetime.now()

    print("ğŸ¬ ãƒ‹ã‚³ãƒ‹ã‚³å‹•ç”»ãƒ©ã‚¤ãƒ–æƒ…å ±å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    
    extractor = NiconicoLiveVideoInfoExtractor()
    
    try:
        # å…¨å‹•ç”»æƒ…å ±ã‚’å–å¾—
        all_videos = extractor.get_all_video_info(CHANNEL_URL)
        
        print(f"\nåˆè¨ˆ {len(all_videos)} å€‹ã®å‹•ç”»æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
        
        # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        extractor.save_to_json(all_videos)
        
        # å–å¾—ã—ãŸæƒ…å ±ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
        if all_videos:
            print("\nå–å¾—ã—ãŸå‹•ç”»æƒ…å ±ã®ã‚µãƒ³ãƒ—ãƒ«:")
            for i, video in enumerate(all_videos[:3]):  # æœ€åˆã®3ä»¶ã‚’è¡¨ç¤º
                print(f"\n--- å‹•ç”» {i+1} ---")
                print(f"ã‚¿ã‚¤ãƒˆãƒ«: {video.get('title', 'N/A')}")
                print(f"å‹•ç”»URL: {video.get('video_url', 'N/A')}")
                print(f"ã‚µãƒ ãƒã‚¤ãƒ«: {video.get('image', 'N/A')}")
                print(f"æ”¾é€é–‹å§‹: {video.get('broadcast_start', 'N/A')}")
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)

    finally:
        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®çµ‚äº†æ™‚é–“ã‚’è¨˜éŒ²
        end_time = datetime.now()
        execution_time = end_time - start_time
        print(f"\nâ± å®Ÿè¡Œæ™‚é–“: {execution_time}")
        print("ğŸ‰ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()

